<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Moritz Hardt – DATASCI 194C/294C</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../styles.css">

    <style>
        /* Speaker layout – conference-style */
        .speaker-section {
            padding: 2rem 0 2.75rem;
        }

        .speaker-card {
            display: flex;
            gap: 1.6rem;
            align-items: flex-start;
            background: var(--card, #f7f7f7);
            border: 1px solid var(--border, #e5e5e5);
            border-radius: 12px;
            padding: 1.4rem 1.6rem;
            margin-bottom: 2.4rem;
        }

        .speaker-photo {
            max-width: 260px;
            width: 100%;
            height: auto;
            border-radius: 10px;
            flex-shrink: 0;
            display: block;
        }

        .speaker-main {
            flex: 1 1 auto;
        }

        .speaker-name {
            margin: 0 0 0.4rem;
            font-size: 1.65rem;
        }

        .speaker-affiliation {
            margin: 0 0 1rem;
            color: var(--muted, #666);
            font-size: 0.95rem;
        }

        .speaker-meta-label {
            font-size: 0.88rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.35rem;
            color: var(--muted, #666);
        }

        .speaker-titles {
            padding-left: 1rem;
            margin: 0 0 0.8rem;
            font-size: 0.95rem;
        }

        .speaker-titles li {
            margin-bottom: 2px;
        }

        .more-info {
            margin-top: 1.5rem;
        }

        /* Mobile optimization */
        @media (max-width: 768px) {
            .container {
                padding-left: 1.3rem;
                padding-right: 1.3rem;
            }

            .speaker-card {
                flex-direction: column;
                align-items: flex-start;
                padding: 1rem 1.2rem;
            }

            .speaker-photo {
                max-width: 200px;
            }
        }
    </style>
</head>

<body>

<header class="topbar">
    <div class="container masthead">
        <div class="title">
            <h1>DATASCI 194C/294C</h1>
        </div>
    </div>
</header>

<div class="container speaker-section">

    <!-- Bio-card -->
    <div class="speaker-card">
        <!-- Replace ../hardt.jpg with your actual filename/path -->
        <img src="../hardt.jpg" alt="Moritz Hardt" class="speaker-photo">

        <div class="speaker-main">
            <h2 class="speaker-name">Moritz Hardt</h2>
            <p class="speaker-affiliation">Max Planck Institute for Intelligent Systems</p>

            <div>
                <div class="speaker-meta-label">Academic Roles</div>
                <ul class="speaker-titles">
                    <li>Director, Social Foundations of Computation, Max Planck Institute for Intelligent Systems, Tübingen</li>
                    <li>Honorary Professor, Tübingen AI Center, University of Tübingen</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Talk details -->
   
    <!-- Talk details -->
<section>
    <h3>Tue • 01/13/2026 – Talk Title</h3>
    <p><strong>Benchmarking in the Golden Era</strong></p>

    <h3>Abstract</h3>
    <p>
        Benchmarking is a process of continual improvement through competitive testing, central
        to engineering communities. Against academic concerns, benchmarking advanced machine
        learning through its heyday, the ImageNet era. Although accuracy numbers varied from one
        dataset to another, model rankings reliably guided progress. Why benchmarking works depends
        on social and psychological patterns invisible from a purely statistical lens.
    </p>
</section>

<section>
    <h3>Thu • 01/15/2026 – Talk Title</h3>
    <p><strong>Why LLMs Broke Benchmarking and What to Salvage</strong></p>

    <h3>Abstract</h3>
    <p>
        After decades of success, benchmarking faces a growing crisis with generative models.
        Different benchmarks give conflicting comparisons, even when targeting the same task.
        Multi-task benchmarks exacerbate ranking disagreements, as do attempts to scale up
        evaluation. Ranking fails when models receive different degrees of task-relevant preparation
        — a problem called training on the test task. Not all is lost, though, and understanding
        precisely what isn’t points to a possible future for benchmarking.
    </p>
</section>


        <h3>Bio</h3>
        <p>
            Moritz Hardt is a Director at the Max Planck Institute for Intelligent Systems in Tübingen.
            Prior to joining the institute, he was an Associate Professor of Electrical Engineering
            and Computer Sciences at the University of California, Berkeley.
        </p>
        <p>
            His research contributes to the scientific foundations of machine learning and
            algorithmic decision making, with a particular focus on social questions arising
            from the deployment and impact of computational systems.
        </p>
    </section>

    <!-- More Information -->
    <section class="more-info">
        <h3>More Information</h3>
        <p>
            Full bio, research and publications available at:
            <a href="https://mrtz.org" target="_blank" rel="noopener noreferrer">
                mrtz.org
            </a>
        </p>
    </section>

</div>

</body>
</html>
