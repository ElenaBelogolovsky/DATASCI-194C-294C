<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Mark Liberman – DATASCI 194C/294C</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../styles.css">

    <style>
        /* Speaker layout – conference-style */
        .speaker-section {
            padding-top: 2rem;
            padding-bottom: 2.5rem;
        }

        .speaker-card {
            display: flex;
            gap: 1.5rem;
            align-items: flex-start;
            background: var(--card, #f7f7f7);
            border: 1px solid var(--border, #e5e5e5);
            border-radius: 12px;
            padding: 1.2rem 1.4rem;
            margin-bottom: 2rem;
        }

        .speaker-photo {
            max-width: 220px;
            border-radius: 10px;
            flex-shrink: 0;
        }

        .speaker-main {
            flex: 1 1 auto;
        }

        .speaker-name {
            margin: 0 0 0.4rem;
            font-size: 1.6rem;
        }

        .speaker-affiliation {
            margin: 0 0 0.8rem;
            color: var(--muted, #666);
            font-size: 0.95rem;
        }

        .speaker-meta-label {
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.25rem;
            color: var(--muted, #666);
        }

        .speaker-titles {
            padding-left: 1rem;
            margin: 0 0 0.5rem;
            font-size: 0.95rem;
        }

        .speaker-titles li {
            margin-bottom: 2px;
        }

        /* Mobile rule matching your Schedule page padding */
        @media (max-width: 768px) {
            .container {
                padding-left: 1.4rem;
                padding-right: 1.4rem;
            }

            .speaker-card {
                flex-direction: column;
                align-items: flex-start;
                padding: 1rem 1.2rem;
            }

            .speaker-photo {
                max-width: 180px;
            }

            h2, h3 {
                margin-left: 0;
                margin-right: 0;
            }
        }
    </style>
</head>

<body>

<header class="topbar">
    <div class="container masthead">
        <div class="title">
            <h1>DATASCI 194C/294C</h1>
        </div>
    </div>
</header>

<div class="container speaker-section">

    <!-- Bio-card -->
    <div class="speaker-card">
        <!-- Update filename if needed -->
        <img src="../liberman.jpg" alt="Mark Liberman" class="speaker-photo">

        <div class="speaker-main">
            <h2 class="speaker-name">Mark Liberman</h2>

            <p class="speaker-affiliation">
                University of Pennsylvania
            </p>

            <div>
                <div class="speaker-meta-label">Academic Roles</div>
                <ul class="speaker-titles">
                    <li><strong>Christopher H. Browne Distinguished Professor of Linguistics</strong></li>
                    <li>Professor, Department of Linguistics</li>
                    <li>Professor, Department of Computer and Information Science</li>
                    <li>Director, Linguistic Data Consortium</li>
                    <li>Faculty Director, Ware College House</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Talk details -->
    <section>
        <h3>Talk Title</h3>
        <p>
            <strong>The Common Task Method: Past, Present, and Future</strong>
        </p>

        <h3>Abstract</h3>

        <p>
            The “Edisonian approach” 
            (<a href="https://arxiv.org/abs/2012.01477" target="_blank" rel="noopener noreferrer">example discussion</a>)
            to invention goes back to the medieval alchemists and beyond – in areas where theory was lacking or incomplete,
            systematic trial and error with quantitative comparison of outcomes was sometimes a practical success.
            After a series of Human Language Technology (HLT) failures, similar methods were applied in the 1970s and 1980s by
            Fred Jelinek’s group at IBM, by George Doddington’s group at Texas Instruments, and by various speech and language
            groups at Bell Labs, MIT, and elsewhere. These researchers shared the Edisonian belief that HLT is an area where
            engineering can precede science, and where learning from large amounts of data is needed.
            In order to make experimental hill-climbing possible, they devised specific simplified tasks, like recognizing
            digit strings, and they designed simple automatically-calculable metrics like “word error rate” and the
            BLEU translation metric
            (<a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">BLEU</a>).
        </p>

        <p>
            Starting in the mid-1980s, (D)ARPA decided to return to HLT after some earlier failed attempts,
            and decided to use quantitative evaluation methods rather than the “evaluation by demonstration”
            that they’d used before. There were some honest believers in the methodology, and others who mainly saw it as
            a way to detect what John Pierce had called “deceit and glamour”
            (<a href="https://iiif.library.cmu.edu/file/Newell_box00030_fld02101_doc0004/Newell_box00030_fld02101_doc0004.pdf"
               target="_blank" rel="noopener noreferrer">Pierce, 1969</a>),
            with the expectation that quantitative failure would soon be followed by program termination.
        </p>

        <p>
            This context required an iterative series of task designs that were easy enough to allow measurable progress,
            hard enough to persuade funders of progress towards the ultimate goals, and cheap enough to start and finish quickly.
            To avoid being trapped by local biases, multiple research groups should be involved, which meant that the data and the
            quantitative evaluation metric should be public. And to achieve these goals, the task design had to be a careful group
            effort, involving funders, potential consumers, and researchers.
        </p>

        <p>This resulted in what came to be known as the “Common Task” structure:</p>
        <ul>
            <li>A detailed task definition and evaluation plan, published as the first step in the project;</li>
            <li>Automatic evaluation software, written and maintained by NIST, and published at the start of the project;</li>
            <li>Shared training and “(dev)elopmental test” data, published at the start of the project;</li>
            <li>“Evaluation test” data withheld and used (once) for periodic public evaluations.</li>
        </ul>

        <p>Although this approach was initially unpopular, it worked – because:</p>
        <ul>
            <li>
                It allowed funding to start (because the projects were perceived as glamour-and-deceit-proof),
                and to continue (because funders could measure progress over time, many years before commercialization);
            </li>
            <li>
                It allowed project-internal hill-climbing, because the metrics were automatic and the code was public;
            </li>
            <li>
                It created a culture, because researchers shared methods and results on shared data with a common metric.
            </li>
        </ul>

        <p>
            And participation in this culture became so valuable that many research groups joined without funding.
            That was the Classical Common Task era, which gave rise to the use of analogous “challenges” across many areas
            of engineering, especially in what is now called “AI”.
        </p>

        <p>
            But some things have been lost in the process, and the practice of “Leaderboard Chasing”
            (<a href="https://drive.google.com/file/d/1rJEPy-1FClKv2mcPKitkxHqs9oHI2RzC/view"
               target="_blank" rel="noopener noreferrer">example critique</a>)
            has been subject to some legitimate criticisms. Similar concerns were well understood 30 or 40 years ago,
            and prompted some of the practices that have since been partly or entirely lost. In this talk,
            I’ll suggest ways to restore and improve the Common Task method in current and future applications.
        </p>

        <h3>More Information</h3>
        <p>
            Full bio, publications, and additional resources available at:
            <a href="https://www.ling.upenn.edu/~myl/" target="_blank" rel="noopener noreferrer">
                https://www.ling.upenn.edu/~myl/
            </a>
        </p>
    </section>
</div>

</body>
</html>
