<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Jacob Steinhardt – DATASCI 194C/294C</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../styles.css">

    <style>
        /* Speaker layout – conference-style */
        .speaker-section {
            padding-top: 2rem;
            padding-bottom: 2.5rem;
        }

        .speaker-card {
            display: flex;
            gap: 1.5rem;
            align-items: flex-start;
            background: var(--card, #f7f7f7);
            border: 1px solid var(--border, #e5e5e5);
            border-radius: 12px;
            padding: 1.2rem 1.4rem;
            margin-bottom: 2rem;
        }

        .speaker-photo {
            max-width: 220px;
            border-radius: 10px;
            flex-shrink: 0;
        }

        .speaker-main {
            flex: 1 1 auto;
        }

        .speaker-name {
            margin: 0 0 0.4rem;
            font-size: 1.6rem;
        }

        .speaker-affiliation {
            margin: 0 0 0.8rem;
            color: var(--muted, #666);
            font-size: 0.95rem;
        }

        .speaker-meta-label {
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.25rem;
            color: var(--muted, #666);
        }

        .speaker-titles {
            padding-left: 1rem;
            margin: 0 0 0.5rem;
            font-size: 0.95rem;
        }

        .speaker-titles li {
            margin-bottom: 2px;
        }

        @media (max-width: 768px) {
            .container {
                padding-left: 1.4rem;
                padding-right: 1.4rem;
            }

            .speaker-card {
                flex-direction: column;
                align-items: flex-start;
                padding: 1rem 1.2rem;
            }

            .speaker-photo {
                max-width: 180px;
            }

            h2, h3 {
                margin-left: 0;
                margin-right: 0;
            }
        }
    </style>
</head>

<body>

<header class="topbar">
    <div class="container masthead">
        <div class="title">
            <h1>DATASCI 194C/294C</h1>
        </div>
    </div>
</header>

<div class="container speaker-section">

    <!-- Bio-card -->
    <div class="speaker-card">
        <img src="../steinhardt.jpg" alt="Jacob Steinhardt" class="speaker-photo">

        <div class="speaker-main">
            <h2 class="speaker-name">Jacob Steinhardt</h2>

            <p class="speaker-affiliation">
                University of California, Berkeley
            </p>

            <div>
                <div class="speaker-meta-label">Academic & Industry Roles</div>
                <ul class="speaker-titles">
                    <li><strong>Assistant Professor, Department of Statistics, UC Berkeley</strong></li>
                    <li>Founder &amp; CEO, Transluce</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Talk details -->
    <section>
        <h3>Talk Title</h3>
        <p><strong>Training Scalable End-to-End Interpretability Assistants</strong></p>

        <h3>Abstract</h3>
        <p>
            The neural representations of transformer models contain rich structure allowing us to debug,
            control, and predict the behavior of AI systems. However, these representations are challenging
            to decipher, owing to their massive scale and self-organized nature. Could we use this same scale
            as a source of leverage, by training AI systems to decipher and explain the representations to us?
        </p>

        <p>
            As a step in this direction, we introduce <em>Predictive Concept Decoders</em>. Given a target model
            that we wish to understand, concept decoders are an auxiliary <em>explainer model</em> trained to
            produce succinct summaries of representations in terms of a model-created token vocabulary.
            To train the encoder, we design a differentiable surrogate loss that approximates how well an
            experienced human could predict model behavior given the summary.
        </p>

        <p>
            I will present our ongoing work constructing concept decoders and scaling them to 100M-token
            pretraining corpora. By training an end-to-end architecture for explaining representations, we
            learn an interpretable and expressive concept dictionary, and use this to introspect on
            fine-grained information within neural representations.
        </p>

        <h3>More Information</h3>
        <p>
            Full faculty page and research at:
            <a href="https://jsteinhardt.stat.berkeley.edu"
               target="_blank" rel="noopener noreferrer">
                https://jsteinhardt.stat.berkeley.edu
            </a>
        </p>
    </section>
</div>

</body>
</html>
